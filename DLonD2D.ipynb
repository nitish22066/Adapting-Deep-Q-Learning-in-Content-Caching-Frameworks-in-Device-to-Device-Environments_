{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DATASET GENERATION"
      ],
      "metadata": {
        "id": "WPn4i6Jq1o9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "M = 10\n",
        "n = 5\n",
        "T = 100\n",
        "\n",
        "\n",
        "cache_sizes = np.random.randint(low=1, high=10, size=M)\n",
        "connection_costs = np.random.rand(M, M)\n",
        "\n",
        "\n",
        "file_requests = np.random.randint(2, size=(T, M, n))\n",
        "cache_decisions = np.random.randint(2, size=(T, M, n))\n",
        "\n",
        "\n",
        "for t in range(1, T):\n",
        "    connection_costs = np.minimum(np.maximum(connection_costs + np.random.uniform(-0.1, 0.1, size=(M, M)), 0), 1)\n",
        "\n",
        "\n",
        "ccutoff = 0.5\n",
        "d2d_neighbors = [\n",
        "    [j for j in range(M) if connection_costs[i, j] <= ccutoff and connection_costs[i, j] <= connection_costs[i, -1]]\n",
        "    for i in range(M)\n",
        "]\n",
        "theta = np.random.randint(2, size=(M, n))\n",
        "\n",
        "d2d_cache_hits_per_user = np.array([\n",
        "    np.sum(file_requests[:, i, :] * (1 - cache_decisions[:, i, :]) * (1 - theta[i, :]) * np.min(connection_costs[i, d2d_neighbors[i]] <= c_cutoff))\n",
        "    for i in range(M)\n",
        "])\n",
        "\n",
        "\n",
        "average_chrd2d = np.mean(d2d_cache_hits_per_user) / (T * n)\n",
        "print(\"Average D2D Cache Hit Ratio:\", average_chrd2d)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUpRrAfy64Ov",
        "outputId": "e194ebdb-6780-4234-c4e7-d2a50fbf1e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average D2D Cache Hit Ratio: 0.11220000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "jAvtk60f1xxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TPXCkJYg1yYs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kP1juO_1xYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-85E2o49HAN",
        "outputId": "e47443e5-2d7d-414f-ed8d-fe11519c4d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "M = 10\n",
        "T = 100\n",
        "\n",
        "\n",
        "connection_costs = np.random.rand(T, M, M)\n",
        "\n",
        "\n",
        "historical_costs = connection_costs[:-1]\n",
        "\n",
        "\n",
        "timesteps = historical_costs.shape[0]\n",
        "features = M * M\n",
        "DX = historical_costs.reshape(timesteps, features, 1)\n",
        "DY = connection_costs[1:].reshape((T-1), M * M)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s6VcgLzv1M8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DtrainX_reshaped = DtrainX.reshape((-1, features))\n",
        "DtestX_reshaped = DtestX.reshape((-1, features))\n",
        "DtrainY_reshaped = DtrainY.reshape((-1, features))\n",
        "DtestY_reshaped = DtestY.reshape((-1, features))\n"
      ],
      "metadata": {
        "id": "GwZ3Pp0VD-0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(features,)),\n",
        "    Dense(features)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')  # Use appropriate loss function\n",
        "\n",
        "\n",
        "model.fit(x=DtrainX_reshaped, y=DtrainY_reshaped, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "\n",
        "predicted_costs = model.predict(DtestX_reshaped)\n",
        "\n",
        "\n",
        "loss = tf.reduce_mean(tf.losses.mean_squared_error(DtestY_reshaped, predicted_costs))\n",
        "\n",
        "print(\"Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iEGEqyyD2m6",
        "outputId": "799119b5-71e8-49b4-b962-e256e973bb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 9ms/step - loss: 0.6075\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4300\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.3290\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2685\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2289\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2014\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1820\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1679\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1581\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1511\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "Loss: tf.Tensor(0.15373024, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ATTENTION FRAMWORK"
      ],
      "metadata": {
        "id": "dbwdVB2W05dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, LSTM, Add, Multiply\n",
        "\n",
        "T = 100\n",
        "M = 500\n",
        "n = 200\n",
        "\n",
        "historical_file_requests = np.random.randint(2, size=(T, M, n))\n",
        "historical_costs = np.random.rand(T, M, M)\n",
        "\n",
        "\n",
        "DX_encoder = historical_file_requests\n",
        "\n",
        "\n",
        "DX_decoder = historical_costs[:-1]\n",
        "\n",
        "\n",
        "DY_attention = historical_costs[1:]\n",
        "\n",
        "DX_encoder_attention = DX_encoder.reshape((T * M, n))\n",
        "DX_decoder_attention = DX_decoder.reshape(((T - 1) * M, M))\n",
        "DY_attention_reshaped = DY_attention.reshape(((T - 1) * M, M))\n",
        "\n",
        "\n",
        "class GatedResidualNetwork(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, dropout_rate=0.1):\n",
        "        super(GatedResidualNetwork, self).__init__()\n",
        "        self.dense_layer = Dense(units, activation='elu')\n",
        "        self.gate_layer = Dense(units, activation='sigmoid')\n",
        "        self.layer_norm = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.dense_layer(inputs)\n",
        "        gate = self.gate_layer(inputs)\n",
        "        x = x * gate\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LayerNormalization, LSTM, Add, Multiply\n",
        "\n",
        "\n",
        "class AttentionModel(tf.keras.Model):\n",
        "    def __init__(self, num_heads, d_model, num_layers, units, dropout_rate):\n",
        "        super(AttentionModel, self).__init__()\n",
        "\n",
        "        self.lstm_encoder = LSTM(units=d_model, return_sequences=True)\n",
        "        self.ln_encoder = LayerNormalization(epsilon=1e-6)\n",
        "        self.grn_encoder = GatedResidualNetwork(units=d_model, dropout_rate=dropout_rate)\n",
        "\n",
        "\n",
        "        self.lstm_decoder = LSTM(units=d_model, return_sequences=True)\n",
        "        self.ln_decoder = LayerNormalization(epsilon=1e-6)\n",
        "        self.grn_decoder = GatedResidualNetwork(units=d_model, dropout_rate=dropout_rate)\n",
        "\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "\n",
        "\n",
        "        self.dense_layer = Dense(units=M * n, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        DX_encoder_attention, DX_decoder_attention = inputs\n",
        "\n",
        "\n",
        "        encoder_output = self.lstm_encoder(DX_encoder_attention)\n",
        "        encoder_output = self.ln_encoder(encoder_output)\n",
        "        encoder_output = self.grn_encoder(encoder_output, training=training)\n",
        "\n",
        "        decoder_output = self.lstm_decoder(DX_decoder_attention)\n",
        "        decoder_output = self.ln_decoder(decoder_output)\n",
        "        decoder_output = self.grn_decoder(decoder_output, training=training)\n",
        "\n",
        "\n",
        "        attn_output = self.multihead_attention(query=decoder_output, value=encoder_output, key=encoder_output)\n",
        "\n",
        "        encoder_output_projected = self.dense_projection(encoder_output)\n",
        "        attn_encoder_mult = attn_output * tf.expand_dims(encoder_output, axis=2)\n",
        "        added_output = attn_encoder_mult + tf.expand_dims(encoder_output, axis=1)\n",
        "        norm_output = LayerNormalization(epsilon=1e-6)(added_output)\n",
        "\n",
        "        attn_decoder_mult = attn_output * tf.expand_dims(decoder_output, axis=2)  # Element-wise multiplication\n",
        "        added_output2 = attn_decoder_mult + tf.expand_dims(norm_output, axis=1)\n",
        "        norm_output2 = LayerNormalization(epsilon=1e-6)(added_output2)\n",
        "\n",
        "        output = self.dense_layer(norm_output2)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "model = AttentionModel(num_heads=4, d_model=64, num_layers=3, units=128, dropout_rate=0.1)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "new_decoder_sequence_length = 300\n",
        "DX_decoder_attention_reshaped = DX_decoder_attention.reshape(((T - 1) * M, new_decoder_sequence_length, M))\n",
        "\n",
        "new_encoder_sequence_length = 150\n",
        "DX_encoder_attention_reshaped = DX_encoder_attention.reshape((T * M, new_encoder_sequence_length, 1))\n",
        "\n",
        "model.fit(x=[DX_encoder_attention_reshaped[0:49500], DX_decoder_attention_reshaped],\n",
        "          y=DY_attention_reshaped, epochs=epochs, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "4CjdJDaxng2S",
        "outputId": "7d514886-577a-4633-d435-98a86191b042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-4e5b837e39ce>\u001b[0m in \u001b[0;36m<cell line: 116>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Changing the shape of the decoder input sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mnew_decoder_sequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mDX_decoder_attention_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDX_decoder_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_decoder_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Changing the shape of the encoder input sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 24750000 into shape (49500,300,500)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DX_encoder_attention_reshaped = DX_encoder_attention.reshape((Timesteps, M, 1)).astype(np.int64)\n",
        "DX_decoder_attention_reshaped = DX_decoder_attention.reshape((Timesteps, M, 1)).astype(np.int64)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x=[DX_encoder_attention_reshaped[0:49500], DX_decoder_attention_reshaped], y=DY_attention_reshaped, epochs=epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "oRD98w74pa6T",
        "outputId": "08d83e65-bd5c-4d18-86f0-ed3dad5b7f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-d7ba4d0e3948>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reshape the data to match the model's input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDX_encoder_attention_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDX_encoder_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mDX_decoder_attention_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDX_decoder_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10000000 into shape (50000,500,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2xHfw2MPzdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UCB1 algorithm"
      ],
      "metadata": {
        "id": "qCsvzdIyz81S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for t in range(test_samples):\n",
        "    for i in range(M):\n",
        "        for j in range(n):\n",
        "\n",
        "            ucb_values = action_values[i] + ucb_parameter * np.sqrt(np.log(train_samples + t + 1) / action_counts[i])\n",
        "\n",
        "\n",
        "            action = np.argmax(ucb_values)\n",
        "            reward = test_d2d_cache_hits_per_user[i, action]\n",
        "\n",
        "\n",
        "            action_counts[i, action] += 1\n",
        "            action_values[i, action] += (reward - action_values[i, action]) / action_counts[i, action]\n",
        "\n",
        "            total_rewards += reward\n",
        "\n",
        "\n",
        "            regret[t, i] = optimal_action_values[i] - test_d2d_cache_hits_per_user[i, action]\n",
        "\n",
        "\n",
        "average_regret = np.mean(regret)\n",
        "\n",
        "\n",
        "loss_ucb1 = total_rewards - np.sum(optimal_action_values) * test_samples * n * M\n",
        "\n",
        "print(\"Average Regret (UCB1):\", average_regret)\n",
        "print(\"Loss (UCB1):\", loss_ucb1)\n",
        "\n",
        "\n",
        "predicted_rewards = np.zeros((test_samples, M, n))\n",
        "for t in range(test_samples):\n",
        "    for i in range(M):\n",
        "        for j in range(n):\n",
        "\n",
        "            ucb_values = action_values[i] + ucb_parameter * np.sqrt(np.log(train_samples + t + 1) / action_counts[i])\n",
        "\n",
        "\n",
        "            action = np.argmax(ucb_values)\n",
        "            predicted_rewards[t, i, j] = action\n",
        "\n",
        "\n",
        "predicted_loss_ucb1 = np.mean(np.square(test_d2d_cache_hits_per_user - predicted_rewards))\n",
        "\n",
        "print(\"Loss for Predicted Rewards (UCB1):\", predicted_loss_ucb1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "sNXhgjAqnNHk",
        "outputId": "b035060f-ab54-4243-eada-103b3830cad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-216-4766369fe45e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# Choose the action with the highest UCB value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mucb_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_d2d_cache_hits_per_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Update action value estimate and count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reshaped_predicted_rewards = predicted_rewards[:, :, 0]\n",
        "predicted_loss_ucb1 = np.mean(np.square(test_d2d_cache_hits_per_user - reshaped_predicted_rewards[0:19]))\n",
        "\n",
        "print(\"Loss for Predicted Rewards (UCB1):\", predicted_loss_ucb1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvetplHfnY3L",
        "outputId": "87bb0f46-8f22-4404-e283-380bda1ecbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Predicted Rewards (UCB1): 3.8796109046137652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "M = 10\n",
        "n = 5\n",
        "T = 100\n",
        "\n",
        "train_size = int(0.8 * M)\n",
        "train_d2d_cache_hits_per_user = d2d_cache_hits_per_user[:train_size]\n",
        "test_d2d_cache_hits_per_user = d2d_cache_hits_per_user[train_size:]\n",
        "\n",
        "\n",
        "action_values = np.zeros((M, n))\n",
        "\n",
        "\n",
        "action_counts = np.zeros((M, n))\n",
        "\n",
        "\n",
        "optimal_action_values = train_d2d_cache_hits_per_user\n",
        "\n",
        "\n",
        "epsilon = 0.1\n",
        "\n",
        "\n",
        "regret = np.zeros((train_size, M))\n",
        "total_rewards = 0\n",
        "\n",
        "\n",
        "for t in range(train_size):\n",
        "    for i in range(train_size):\n",
        "        if np.random.rand() < epsilon:\n",
        "\n",
        "            action = np.random.choice(n)\n",
        "        else:\n",
        "\n",
        "            action = np.argmax(action_values[i])\n",
        "\n",
        "        reward = train_d2d_cache_hits_per_user[i]\n",
        "\n",
        "\n",
        "        action_counts[i, action] += 1\n",
        "        action_values[i, action] += (reward - action_values[i, action]) / action_counts[i, action]\n",
        "\n",
        "        total_rewards += reward\n",
        "\n",
        "\n",
        "        regret[t, i] = optimal_action_values[i] - reward\n",
        "\n",
        "predicted_rewards = np.zeros_like(test_d2d_cache_hits_per_user)\n",
        "\n",
        "for t in range(test_d2d_cache_hits_per_user.shape[0]):\n",
        "    for i in range(train_size, M):\n",
        "        action = np.argmax(action_values[i])\n",
        "\n",
        "\n",
        "        predicted_rewards[t] = action_values[i, action]\n",
        "\n",
        "\n",
        "predicted_loss_contextual = np.mean(np.square(test_d2d_cache_hits_per_user - predicted_rewards))\n",
        "\n",
        "print(\"Loss for Predicted Rewards (Contextual Bandits):\", predicted_loss_contextual)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbRpa5_UxX0b",
        "outputId": "24e570c9-0d3b-44f9-9ac5-5fb769ea261e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Predicted Rewards (Contextual Bandits): 2658.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZKl4yTJxfgv",
        "outputId": "8497e597-793e-47cb-c539-2de153b11027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_d2d_cache_hits_per_user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sODCjBK1xx-r",
        "outputId": "f433d0fb-09fa-4119-944f-b52454a544b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([49, 54])"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    }
  ]
}